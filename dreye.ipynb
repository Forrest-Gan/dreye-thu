{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Flatten, concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Conv2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Reshape\n",
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters (no need to edit)\n",
    "t, c, w, h = 16, 3, 112, 112\n",
    "upsample = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoarse2FineModel(summary=True):\n",
    "\n",
    "    # defined input\n",
    "    videoclip_cropped = Input((t, h, w, c), name='input1')\n",
    "    videoclip_original = Input((t, h, w, c), name='input2')\n",
    "    last_frame_bigger = Input(( h*upsample, w*upsample, c), name='input3')\n",
    "  \n",
    "\n",
    "    # coarse saliency model\n",
    "    coarse_saliency_model = Sequential()\n",
    "    coarse_saliency_model.add(Conv3D(64, [3, 3, 3], activation='relu', padding='same', name='conv1', strides=(1, 1, 1), data_format='channels_last'))\n",
    "    coarse_saliency_model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), padding='valid', name='pool1',data_format='channels_last'))\n",
    "    coarse_saliency_model.add(Conv3D(128, [3, 3, 3], activation='relu', padding='same', name='conv2', strides=(1, 1, 1), data_format='channels_last'))\n",
    "    coarse_saliency_model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', name='pool2',data_format='channels_last'))\n",
    "    coarse_saliency_model.add(Conv3D(256, [3, 3, 3], activation='relu', padding='same', name='conv3a', strides=(1, 1, 1), data_format='channels_last'))\n",
    "    coarse_saliency_model.add(Conv3D(256, [3, 3, 3], activation='relu', padding='same', name='conv3b', strides=(1, 1, 1), data_format='channels_last'))\n",
    "    coarse_saliency_model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', name='pool3',data_format='channels_last'))\n",
    "    coarse_saliency_model.add(Conv3D(512, [3, 3, 3], activation='relu', padding='same', name='conv4a', strides=(1, 1, 1), data_format='channels_last'))\n",
    "    coarse_saliency_model.add(Conv3D(512, [3, 3, 3], activation='relu', padding='same', name='conv4b', strides=(1, 1, 1), data_format='channels_last'))\n",
    "    coarse_saliency_model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(4, 2, 2), padding='valid', name='pool4',data_format='channels_last'))\n",
    "    coarse_saliency_model.add(Reshape((512, 7, 7)))\n",
    "    coarse_saliency_model.add(BatchNormalization())\n",
    "    coarse_saliency_model.add(Conv2D(256, [3, 3], kernel_initializer='glorot_uniform', padding='same',data_format='channels_last'))\n",
    "    coarse_saliency_model.add(LeakyReLU(alpha=.001))\n",
    "    coarse_saliency_model.add(UpSampling2D(size=(2, 2), data_format='channels_last'))\n",
    "    coarse_saliency_model.add(BatchNormalization())\n",
    "    coarse_saliency_model.add(Conv2D(128, [3, 3], kernel_initializer='glorot_uniform', padding='same',data_format='channels_last'))\n",
    "    coarse_saliency_model.add(LeakyReLU(alpha=.001))\n",
    "    coarse_saliency_model.add(UpSampling2D(size=(2, 2), data_format='channels_last'))\n",
    "    coarse_saliency_model.add(BatchNormalization())\n",
    "    coarse_saliency_model.add(Conv2D(64, [3, 3], kernel_initializer='glorot_uniform', padding='same',data_format='channels_last'))\n",
    "    coarse_saliency_model.add(LeakyReLU(alpha=.001))\n",
    "    coarse_saliency_model.add(UpSampling2D(size=(2, 2), data_format='channels_last'))\n",
    "    coarse_saliency_model.add(BatchNormalization())\n",
    "    coarse_saliency_model.add(Conv2D(32, [3, 3], kernel_initializer='glorot_uniform', padding='same',data_format='channels_last'))\n",
    "    coarse_saliency_model.add(LeakyReLU(alpha=.001))\n",
    "    coarse_saliency_model.add(UpSampling2D(size=(2, 2), data_format='channels_last'))\n",
    "    coarse_saliency_model.add(BatchNormalization())\n",
    "    coarse_saliency_model.add(Conv2D(16, [3, 3], kernel_initializer='glorot_uniform', padding='same',data_format='channels_last'))\n",
    "    coarse_saliency_model.add(LeakyReLU(alpha=.001))\n",
    "    coarse_saliency_model.add(BatchNormalization())\n",
    "    coarse_saliency_model.add(Conv2D(1, [3, 3], kernel_initializer='glorot_uniform', padding='same',data_format='channels_last'))\n",
    "    coarse_saliency_model.add(LeakyReLU(alpha=.001))\n",
    "\n",
    "    # loss on cropped image\n",
    "    coarse_saliency_cropped = coarse_saliency_model(videoclip_cropped)\n",
    "    cropped_output = Flatten(name='cropped_output')(coarse_saliency_cropped)\n",
    "\n",
    "    # coarse-to-fine saliency model and loss\n",
    "    coarse_saliency_original = coarse_saliency_model(videoclip_original)\n",
    "\n",
    "    x = UpSampling2D((upsample, upsample), name='coarse_saliency_upsampled', data_format='channels_last')(coarse_saliency_original)  # 112 x 4 = 448\n",
    "    \n",
    "    x = concatenate([x, last_frame_bigger],axis=1)  # merge the last RGB frame\n",
    "\n",
    "    x = Conv2D(32, [3, 3], padding='same', kernel_initializer='he_normal',data_format='channels_last')(x)\n",
    "    x = Conv2D(64, [3, 3], padding='same', kernel_initializer='he_normal',data_format='channels_last')(x)\n",
    "    x = LeakyReLU(alpha=.001)(x)\n",
    "    x = Conv2D(32, [3, 3], padding='same', kernel_initializer='he_normal', data_format='channels_last')(x)\n",
    "    x = LeakyReLU(alpha=.001)(x)\n",
    "    x = Conv2D(32, [3, 3], padding='same', kernel_initializer='he_normal' ,data_format='channels_last')(x)\n",
    "    x = LeakyReLU(alpha=.001)(x)\n",
    "    x = Conv2D(16, [3, 3], padding='same', kernel_initializer='he_normal', data_format='channels_last')(x)\n",
    "    x = LeakyReLU(alpha=.001)(x)\n",
    "    x = Conv2D(4, [3, 3], padding='same', kernel_initializer='he_normal', data_format='channels_last')(x)\n",
    "    x = LeakyReLU(alpha=.001)(x)\n",
    "\n",
    "    fine_saliency_model = Conv2D(1, [3, 3], padding='same', activation='relu', data_format='channels_last')(x)\n",
    "\n",
    "    # loss on full image\n",
    "    full_fine_output = Flatten(name='full_fine_output')(fine_saliency_model)\n",
    "\n",
    "    final_model = Model(inputs=[videoclip_cropped, videoclip_original, last_frame_bigger],\n",
    "                        outputs=[cropped_output, full_fine_output])\n",
    "\n",
    "    if summary:\n",
    "        print (final_model.summary())\n",
    "\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_video(model, folder_in, output_path, mean_frame_path):\n",
    "\n",
    "    # load frames to predict\n",
    "    frames = []\n",
    "    frame_list = os.listdir(folder_in)\n",
    "    mean_frame = cv2.imread(mean_frame_path)\n",
    "    print(mean_frame.shape)\n",
    "    for frame_name in frame_list:\n",
    "        frame = cv2.imread(join(folder_in, frame_name))\n",
    "        frames.append(frame.astype(np.float32) - mean_frame)\n",
    "    print ('Done loading frames.')\n",
    "\n",
    "    # start of prediction\n",
    "    for i in range(t, len(frames)):\n",
    "\n",
    "        sys.stdout.write('\\r{0}: predicting on frame {1:06d}...'.format(folder_in, i))\n",
    "\n",
    "        # loading videoclip of t frames\n",
    "        x = np.array(frames[i - t: i])\n",
    "\n",
    "        x_last_bigger = cv2.resize(x[-1, :, :, :], (h*upsample,w*upsample))\n",
    "        x_last_bigger = x_last_bigger.transpose(2, 0, 1)\n",
    "        x_last_bigger = x_last_bigger[None, :]\n",
    "\n",
    "        x = np.array([cv2.resize(f, (h, w)) for f in x])\n",
    "        x = x[None, :]\n",
    "        x = x.transpose(0, 4, 1, 2, 3).astype(np.float32)\n",
    "\n",
    "        # predict attentional map on last frame of the videoclip\n",
    "        res = model.predict_on_batch([x, x, x_last_bigger])\n",
    "        res = res[1]  # keep only fine output\n",
    "        res = np.clip(res, a_min=0, a_max=255)\n",
    "\n",
    "        # normalize attentional map between 0 and 1\n",
    "        res_norm = ((res / res.max()) * 255).astype(np.uint8)\n",
    "        res_norm = np.reshape(res_norm, (h*upsample,w*upsample))\n",
    "\n",
    "        cv2.imwrite(join(output_path, '{0:06d}.png'.format(i)), res_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input1 (InputLayer)             [(None, 3, 16, 112,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 3, 16, 112,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 1, 112, 112)  15072421    input1[0][0]                     \n",
      "                                                                 input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "coarse_saliency_upsampled (UpSa (None, 1, 448, 448)  0           sequential[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input3 (InputLayer)             [(None, 3, 448, 448) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4, 448, 448)  0           coarse_saliency_upsampled[0][0]  \n",
      "                                                                 input3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 448, 448) 1184        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 448, 448) 18496       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64, 448, 448) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 448, 448) 18464       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 32, 448, 448) 0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 448, 448) 9248        leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 32, 448, 448) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 448, 448) 4624        leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 16, 448, 448) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 448, 448)  580         leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 4, 448, 448)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 1, 448, 448)  37          leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cropped_output (Flatten)        (None, 12544)        0           sequential[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "full_fine_output (Flatten)      (None, 200704)       0           conv2d_12[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,125,054\n",
      "Trainable params: 15,124,396\n",
      "Non-trainable params: 658\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from utils import getCoarse2FineModel, predict_video\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    mean_frame = cv2.imread('data_sample/dreyeve_mean_frame.png')\n",
    "    print(mean_frame.shape)\n",
    "    \n",
    "    output_dir_root = 'out'\n",
    "    weights_file = 'weights/model_weights.h5'\n",
    "    dreyeve_data_dir = 'data_sample/54'\n",
    "\n",
    "    # load model for prediction\n",
    "    model = getCoarse2FineModel(summary=True)\n",
    "    opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss={'cropped_output': 'mse', 'full_fine_output': 'mse'},\n",
    "                  loss_weights={'cropped_output': 1.0, 'full_fine_output': 1.0})\n",
    "\n",
    "    # load pre-trained weights\n",
    "    #model.load_weights(weights_file)\n",
    "\n",
    "    # predict on sample data (first 200 frames of run 54 from DR(eye)VE\n",
    "    #predict_video(model, dreyeve_data_dir,\n",
    "    #              output_path=output_dir_root,\n",
    "    #              mean_frame_path='data_sample/dreyeve_mean_frame.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
